from fastapi import APIRouter, Query, HTTPException, Request, Response
from app.services import pinecone_client, embeddings, llm
from pydantic import BaseModel
from typing import Optional, Dict, List
import re
import os
from openai import OpenAI
from dotenv import load_dotenv
import json
from datetime import datetime

load_dotenv()

# In-memory conversation history storage (for demo purposes) need to use other db for context storage 
conversation_history: Dict[str, List[Dict]] = {}

router = APIRouter()

class ChatRequest(BaseModel):
    query: str
    session_id: Optional[str] = None

def get_or_create_session_id(session_id: Optional[str]) -> str:
    """Get existing session_id or create a new one"""
    if not session_id:
        import uuid
        session_id = str(uuid.uuid4())
    
    if session_id not in conversation_history:
        conversation_history[session_id] = []
    
    return session_id

def add_to_conversation_history(session_id: str, user_query: str, bot_response: str, language: str):
    """Add conversation turn to history"""
    conversation_history[session_id].append({
        "timestamp": datetime.now().isoformat(),
        "user_query": user_query,
        "bot_response": bot_response,
        "language": language
    })
    
    # Keep only last 10 conversation turns to avoid memory issues
    if len(conversation_history[session_id]) > 10:
        conversation_history[session_id] = conversation_history[session_id][-10:]

def get_conversation_context(session_id: str, language: str) -> str:
    """Get recent conversation context for the LLM"""
    if session_id not in conversation_history or not conversation_history[session_id]:
        return ""
    
    recent_turns = conversation_history[session_id][-4:]  # Last 4 turns for better performance
    
    context_parts = []
    for turn in recent_turns:
        context_parts.append(f"Previous Q: {turn['user_query']}")
        context_parts.append(f"Previous A: {turn['bot_response']}")
    
    context = "\n".join(context_parts)
    
    # Add language-specific instruction
    language_instructions = {
        'english': "Consider the previous conversation context when answering. Reference previous questions and answers when relevant.",
        'hindi': "‡§™‡§ø‡§õ‡§≤‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•á ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ï‡•ã ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡§§‡•á ‡§π‡•Å‡§è ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§Ç‡•§ ‡§ú‡§¨ ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§π‡•ã ‡§§‡•ã ‡§™‡§ø‡§õ‡§≤‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§®‡•ã‡§Ç ‡§î‡§∞ ‡§â‡§§‡•ç‡§§‡§∞‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§¶‡•á‡§Ç‡•§",
        'telugu': "‡∞Æ‡±Å‡∞®‡±Å‡∞™‡∞ü‡∞ø ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£ ‡∞∏‡∞Ç‡∞¶‡∞∞‡±ç‡∞≠‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞®‡∞≤‡±ã‡∞ï‡∞ø ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±ä‡∞®‡∞ø ‡∞ú‡∞µ‡∞æ‡∞¨‡±Å ‡∞á‡∞µ‡±ç‡∞µ‡∞Ç‡∞°‡∞ø. ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§‡∞Æ‡±à‡∞®‡∞™‡±ç‡∞™‡±Å‡∞°‡±Å ‡∞Æ‡±Å‡∞®‡±Å‡∞™‡∞ü‡∞ø ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡±Å ‡∞Æ‡∞∞‡∞ø‡∞Ø‡±Å ‡∞ú‡∞µ‡∞æ‡∞¨‡±Å‡∞≤‡∞®‡±Å ‡∞∏‡±Ç‡∞ö‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø.",
        'kannada': "‡≤π‡≤ø‡≤Ç‡≤¶‡≤ø‡≤® ‡≤∏‡≤Ç‡≤≠‡≤æ‡≤∑‡≤£‡≥Ü‡≤Ø ‡≤∏‡≤Ç‡≤¶‡≤∞‡≥ç‡≤≠‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤ó‡≤£‡≤ø‡≤∏‡≤ø ‡≤â‡≤§‡≥ç‡≤§‡≤∞‡≤ø‡≤∏‡≤ø. ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤ø‡≤§‡≤µ‡≤æ‡≤¶‡≤æ‡≤ó ‡≤π‡≤ø‡≤Ç‡≤¶‡≤ø‡≤® ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤â‡≤§‡≥ç‡≤§‡≤∞‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤â‡≤≤‡≥ç‡≤≤‡≥á‡≤ñ‡≤ø‡≤∏‡≤ø.",
        'marathi': "‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§ö‡§æ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§≤‡§ï‡•ç‡§∑‡§æ‡§§ ‡§ò‡•á‡§ä‡§® ‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•ç‡§Ø‡§æ. ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§Ö‡§∏‡§≤‡•ç‡§Ø‡§æ‡§∏ ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§Ü‡§£‡§ø ‡§â‡§§‡•ç‡§§‡§∞‡§æ‡§Ç‡§ö‡§æ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§¶‡•ç‡§Ø‡§æ."
    }
    
    instruction = language_instructions.get(language, language_instructions['english'])
    return f"{instruction}\n\nPrevious conversation:\n{context}\n\n"

def get_structured_conversation_messages(session_id: str, language: str) -> list[Dict[str, str]]:
    """Return structured chat messages from recent history for LLM consumption"""
    if session_id not in conversation_history or not conversation_history[session_id]:
        return []

    language_instructions = {
        'english': "Consider the prior conversation turns when answering.",
        'hindi': "‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§§‡•á ‡§∏‡§Æ‡§Ø ‡§™‡§ø‡§õ‡§≤‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡•ã ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡•á‡§Ç‡•§",
        'telugu': "‡∞Æ‡±Å‡∞®‡±Å‡∞™‡∞ü‡∞ø ‡∞∏‡∞Ç‡∞≠‡∞æ‡∞∑‡∞£‡∞®‡±Å ‡∞™‡∞∞‡∞ø‡∞ó‡∞£‡∞®‡∞≤‡±ã‡∞ï‡∞ø ‡∞§‡±Ä‡∞∏‡±Å‡∞ï‡±ã‡∞Ç‡∞°‡∞ø.",
        'kannada': "‡≤π‡≤ø‡≤Ç‡≤¶‡≤ø‡≤® ‡≤∏‡≤Ç‡≤≠‡≤æ‡≤∑‡≤£‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≤ø‡≤ó‡≤£‡≤ø‡≤∏‡≤ø.",
        'marathi': "‡§â‡§§‡•ç‡§§‡§∞ ‡§¶‡•á‡§§‡§æ‡§®‡§æ ‡§Æ‡§æ‡§ó‡•Ä‡§≤ ‡§∏‡§Ç‡§≠‡§æ‡§∑‡§£‡§æ‡§ö‡§æ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§æ."
    }
    system_note = language_instructions.get(language, language_instructions['english'])

    # Pull recent turns for continuity but keep cap reasonable for performance
    recent_turns = conversation_history[session_id][-4:]

    messages: list[Dict[str, str]] = []
    # Add a lightweight system reminder specific to history consideration
    messages.append({"role": "system", "content": system_note})
    for turn in recent_turns:
        messages.append({"role": "user", "content": turn["user_query"]})
        messages.append({"role": "assistant", "content": turn["bot_response"]})
    return messages

def detect_language_and_greeting(text: str) -> tuple[bool, str]:
    """Detect if text is a greeting and return the detected language"""
    text_lower = text.lower().strip()
    
    # Use LLM to detect if it's a greeting and what language
    try:
        openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a language detection expert. Analyze the given text and determine: 1) Is this a greeting or casual conversation starter? 2) What language is it in? Respond with only: GREETING:true/false,LANGUAGE:english/hindi/telugu/kannada/marathi"
                },
                {"role": "user", "content": text}
            ],
            max_tokens=30,  # Reduced for faster response
            temperature=0.1  # Lower temperature for faster, more consistent responses
        )
        
        result = response.choices[0].message.content.lower()
        
        # Parse the response
        is_greeting = "greeting:true" in result
        language = "english"  # default
        
        if "language:hindi" in result:
            language = "hindi"
        elif "language:telugu" in result:
            language = "telugu"
        elif "language:kannada" in result:
            language = "kannada"
        elif "language:marathi" in result:
            language = "marathi"
        
        return is_greeting, language
        
    except Exception:
        # Fallback to simple pattern matching if LLM fails
        return detect_greeting_fallback(text)



def detect_greeting_fallback(text: str) -> tuple[bool, str]:
    """Fallback greeting detection using simple patterns"""
    text_lower = text.lower().strip()
    
    # Simple greeting patterns
    greeting_patterns = [
        (r'\b(hi|hello|hey|good morning|good afternoon|good evening|how are you|how do you do|jai srimannarayana)\b', 'english'),
        (r'\b(namaste|namaskar|pranam|kaise ho|kaise hain|jai srimannarayana)\b', 'hindi'),
        (r'\b(namaskaram|namaskaramu|bagunnara|ela unnaru|ela unnavu|jai srimannarayana)\b', 'telugu'),
        (r'\b(namaskara|howdu|chennagideya|jai srimannarayana)\b', 'kannada'),
        (r'\b(namaskar|kasa ahes|kasa aahes|jai srimannarayana)\b', 'marathi')
    ]
    
    for pattern, language in greeting_patterns:
        if re.search(pattern, text_lower):
            return True, language
    
    # Detect language from content
    detected_language = detect_language_from_content(text)
    return False, detected_language

def detect_language_from_content(text: str) -> str:
    """Detect language from text content using Unicode ranges and common words"""
    text_lower = text.lower()
    
    # Check for Telugu Unicode range (0C00-0C7F)
    if any('\u0c00' <= char <= '\u0c7f' for char in text):
        return 'telugu'
    
    # Check for Hindi/Devanagari Unicode range (0900-097F)
    if any('\u0900' <= char <= '\u097f' for char in text):
        # Check for Marathi-specific words
        marathi_words = ['ahes', 'aahes', 'kasa', 'kase', 'kasa ahes', 'marathi', 'maharashtra']
        if any(word in text_lower for word in marathi_words):
            return 'marathi'
        return 'hindi'
    
    # Check for Kannada Unicode range (0C80-0CFF)
    if any('\u0c80' <= char <= '\u0cff' for char in text):
        return 'kannada'
    
    # Fallback to word-based detection for English text
    telugu_words = ['telugu', 'andhra', 'telangana', 'garu', 'unnaru', 'unnavu', 'ela', 'baga', 'bagunnara']
    if any(word in text_lower for word in telugu_words):
        return 'telugu'
    
    kannada_words = ['kannada', 'karnataka', 'guru', 'deya', 'howdu', 'chennagi', 'chennagideya']
    if any(word in text_lower for word in kannada_words):
        return 'kannada'
    
    hindi_words = ['hindi', 'hain', 'ho', 'aap', 'tum', 'kaise', 'kya', 'hai', 'kya hai']
    if any(word in text_lower for word in hindi_words):
        return 'hindi'
    
    marathi_words = ['marathi', 'maharashtra', 'ahes', 'aahes', 'kasa', 'kase', 'kasa ahes']
    if any(word in text_lower for word in marathi_words):
        return 'marathi'
    
    # Default to English
    return 'english'

def get_greeting_response(language: str, user_query: str = "") -> str:
    """Get natural greeting response in the detected language"""
    try:
        # Use LLM to generate natural greeting response
        openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": f"You are a friendly Bhagavad Gita chatbot. The user greeted you in {language}. Respond naturally with 'Jai Srimannarayana' and acknowledge their greeting, then ask how you can help them learn about the Bhagavad Gita. Be conversational and warm. Respond in {language}."
                },
                {"role": "user", "content": user_query}
            ],
            max_tokens=80,  # Reduced for faster response
            temperature=0.3  # Lower temperature for faster, more consistent responses
        )
        return response.choices[0].message.content
    except Exception:
        # Fallback responses with multiple variations
        import random
        responses = {
            'english': [
                "Jai Srimannarayana! üôè I'm doing well, thank you for asking! How can I help you learn about the Bhagavad Gita today?",
                "Jai Srimannarayana! üôè I'm fine, thanks for your concern! What would you like to know about the Bhagavad Gita?",
                "Jai Srimannarayana! üôè All is well, thank you! How may I assist you with the teachings of the Bhagavad Gita?",
                "Jai Srimannarayana! üôè I'm doing great! What questions do you have about Krishna's wisdom in the Gita?",
                "Jai Srimannarayana! üôè Everything is wonderful, thank you! How can I help you explore the Bhagavad Gita today?"
            ],
            'hindi': [
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§Æ‡•à‡§Ç ‡§†‡•Ä‡§ï ‡§π‡•Ç‡§Ç, ‡§™‡•Ç‡§õ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§∏‡•Ä‡§ñ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§Æ‡•à‡§Ç ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•Ç‡§Ç, ‡§Ü‡§™‡§ï‡•Ä ‡§ö‡§ø‡§Ç‡§§‡§æ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§†‡•Ä‡§ï ‡§π‡•à, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•Ä ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡•à‡§∏‡•á ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§Æ‡•à‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§π‡•Ç‡§Ç! ‡§ó‡•Ä‡§§‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡•É‡§∑‡•ç‡§£ ‡§ï‡•Ä ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§π‡•à‡§Ç?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§∂‡§æ‡§®‡§¶‡§æ‡§∞ ‡§π‡•à, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Ü‡§ú ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡§æ ‡§Ö‡§®‡•ç‡§µ‡•á‡§∑‡§£ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Ç?"
            ],
            'telugu': [
                "‡∞ú‡±à ‡∞∂‡±ç‡∞∞‡±Ä‡∞Æ‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ‡∞Ø‡∞£! üôè ‡∞®‡±á‡∞®‡±Å ‡∞¨‡∞æ‡∞ó‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å, ‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞®‡∞Ç‡∞¶‡±Å‡∞ï‡±Å ‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å! ‡∞®‡±á‡∞®‡±Å ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞®‡±á‡∞∞‡±ç‡∞ö‡±Å‡∞ï‡±ã‡∞µ‡∞°‡∞Ç‡∞≤‡±ã ‡∞é‡∞≤‡∞æ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞™‡∞°‡∞ó‡∞≤‡∞®‡±Å?",
                "‡∞ú‡±à ‡∞∂‡±ç‡∞∞‡±Ä‡∞Æ‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ‡∞Ø‡∞£! üôè ‡∞®‡±á‡∞®‡±Å ‡∞ö‡∞ï‡±ç‡∞ï‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å, ‡∞Æ‡±Ä ‡∞Ü‡∞Ç‡∞¶‡±ã‡∞≥‡∞®‡∞ï‡±Å ‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å! ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞è‡∞Æ‡∞ø ‡∞§‡±Ü‡∞≤‡±Å‡∞∏‡±Å‡∞ï‡±ã‡∞µ‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?",
                "‡∞ú‡±à ‡∞∂‡±ç‡∞∞‡±Ä‡∞Æ‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ‡∞Ø‡∞£! üôè ‡∞Ö‡∞®‡±ç‡∞®‡±Ä ‡∞¨‡∞æ‡∞ó‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø, ‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å! ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞¨‡±ã‡∞ß‡∞®‡∞≤‡∞≤‡±ã ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞®‡±á‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞™‡∞°‡∞ó‡∞≤‡∞®‡±Å?",
                "‡∞ú‡±à ‡∞∂‡±ç‡∞∞‡±Ä‡∞Æ‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ‡∞Ø‡∞£! üôè ‡∞®‡±á‡∞®‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞¨‡∞æ‡∞ó‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å! ‡∞ó‡±Ä‡∞§‡∞≤‡±ã ‡∞ï‡±É‡∞∑‡±ç‡∞£‡±Å‡∞°‡∞ø ‡∞ú‡±ç‡∞û‡∞æ‡∞®‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡±Å ‡∞è‡∞Æ‡∞ø‡∞ü‡∞ø?",
                "‡∞ú‡±à ‡∞∂‡±ç‡∞∞‡±Ä‡∞Æ‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ‡∞Ø‡∞£! üôè ‡∞Ö‡∞®‡±ç‡∞®‡±Ä ‡∞Ö‡∞¶‡±ç‡∞≠‡±Å‡∞§‡∞Ç‡∞ó‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞Ø‡∞ø, ‡∞ß‡∞®‡±ç‡∞Ø‡∞µ‡∞æ‡∞¶‡∞æ‡∞≤‡±Å! ‡∞à‡∞∞‡±ã‡∞ú‡±Å ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§‡∞®‡±Å ‡∞Ö‡∞®‡±ç‡∞µ‡±á‡∞∑‡∞ø‡∞Ç‡∞ö‡∞°‡∞Ç‡∞≤‡±ã ‡∞Æ‡±Ä‡∞ï‡±Å ‡∞®‡±á‡∞®‡±Å ‡∞é‡∞≤‡∞æ ‡∞∏‡∞π‡∞æ‡∞Ø‡∞™‡∞°‡∞ó‡∞≤‡∞®‡±Å?"
            ],
            'kannada': [
                "‡≤ú‡≥à ‡≤∂‡≥ç‡≤∞‡≥Ä‡≤Æ‡≤®‡≥ç‡≤®‡≤æ‡≤∞‡≤æ‡≤Ø‡≤£! üôè ‡≤®‡≤æ‡≤®‡≥Å ‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü, ‡≤ï‡≥á‡≤≥‡≤ø‡≤¶‡≤ï‡≥ç‡≤ï‡≤æ‡≤ó‡≤ø ‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å! ‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤ï‡≤≤‡≤ø‡≤Ø‡≤≤‡≥Å ‡≤π‡≥á‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≤¨‡≤π‡≥Å‡≤¶‡≥Å?",
                "‡≤ú‡≥à ‡≤∂‡≥ç‡≤∞‡≥Ä‡≤Æ‡≤®‡≥ç‡≤®‡≤æ‡≤∞‡≤æ‡≤Ø‡≤£! üôè ‡≤®‡≤æ‡≤®‡≥Å ‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü, ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤ï‡≤æ‡≤≥‡≤ú‡≤ø‡≤ó‡≥Ü ‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å! ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤è‡≤®‡≥Å ‡≤§‡≤ø‡≤≥‡≤ø‡≤¶‡≥Å‡≤ï‡≥ä‡≤≥‡≥ç‡≤≥‡≤≤‡≥Å ‡≤¨‡≤Ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥Ä‡≤∞‡≤ø?",
                "‡≤ú‡≥à ‡≤∂‡≥ç‡≤∞‡≥Ä‡≤Æ‡≤®‡≥ç‡≤®‡≤æ‡≤∞‡≤æ‡≤Ø‡≤£! üôè ‡≤é‡≤≤‡≥ç‡≤≤‡≤µ‡≥Ç ‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü, ‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å! ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤¨‡≥ã‡≤ß‡≤®‡≥Ü‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤π‡≥á‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≤¨‡≤π‡≥Å‡≤¶‡≥Å?",
                "‡≤ú‡≥à ‡≤∂‡≥ç‡≤∞‡≥Ä‡≤Æ‡≤®‡≥ç‡≤®‡≤æ‡≤∞‡≤æ‡≤Ø‡≤£! üôè ‡≤®‡≤æ‡≤®‡≥Å ‡≤§‡≥Å‡≤Ç‡≤¨‡≤æ ‡≤ö‡≥Ü‡≤®‡≥ç‡≤®‡≤æ‡≤ó‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤®‡≥Ü! ‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤ï‡≥É‡≤∑‡≥ç‡≤£‡≤® ‡≤¨‡≥Å‡≤¶‡≥ç‡≤ß‡≤ø‡≤µ‡≤Ç‡≤§‡≤ø‡≤ï‡≥Ü‡≤Ø ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≥Å ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤µ‡≥Å?",
                "‡≤ú‡≥à ‡≤∂‡≥ç‡≤∞‡≥Ä‡≤Æ‡≤®‡≥ç‡≤®‡≤æ‡≤∞‡≤æ‡≤Ø‡≤£! üôè ‡≤é‡≤≤‡≥ç‡≤≤‡≤µ‡≥Ç ‡≤Ö‡≤¶‡≥ç‡≤≠‡≥Å‡≤§‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü, ‡≤ß‡≤®‡≥ç‡≤Ø‡≤µ‡≤æ‡≤¶‡≤ó‡≤≥‡≥Å! ‡≤á‡≤Ç‡≤¶‡≥Å ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤®‡≥ç‡≤µ‡≥á‡≤∑‡≤ø‡≤∏‡≤≤‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤®‡≤ø‡≤Æ‡≤ó‡≥Ü ‡≤π‡≥á‡≤ó‡≥Ü ‡≤∏‡≤π‡≤æ‡≤Ø ‡≤Æ‡≤æ‡≤°‡≤¨‡≤π‡≥Å‡≤¶‡≥Å?"
            ],
            'marathi': [
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§Æ‡•Ä ‡§†‡•Ä‡§ï ‡§Ü‡§π‡•á, ‡§µ‡§ø‡§ö‡§æ‡§∞‡§≤‡•ç‡§Ø‡§æ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§∂‡§ø‡§ï‡§£‡•ç‡§Ø‡§æ‡§§ ‡§ï‡§∂‡•Ä ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§§‡•ã?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§Æ‡•Ä ‡§ö‡§æ‡§Ç‡§ó‡§≤‡•á ‡§Ü‡§π‡•á, ‡§§‡•Å‡§Æ‡§ö‡•ç‡§Ø‡§æ ‡§ï‡§æ‡§≥‡§ú‡•Ä‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡§æ‡§Ø ‡§ú‡§æ‡§£‡•Ç‡§® ‡§ò‡•ç‡§Ø‡§æ‡§Ø‡§ö‡•á ‡§Ü‡§π‡•á?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§∏‡§∞‡•ç‡§µ ‡§ï‡§æ‡§π‡•Ä ‡§†‡•Ä‡§ï ‡§Ü‡§π‡•á, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡•á‡§ö‡•ç‡§Ø‡§æ ‡§∂‡§ø‡§ï‡§µ‡§£‡•Ä‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡§∂‡•Ä ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§§‡•ã?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§Æ‡•Ä ‡§ñ‡•Ç‡§™ ‡§ö‡§æ‡§Ç‡§ó‡§≤‡•á ‡§Ü‡§π‡•á! ‡§ó‡•Ä‡§§‡•á‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ï‡•É‡§∑‡•ç‡§£‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡•á‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§§‡•Å‡§Æ‡§ö‡•á ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡§æ‡§Ø ‡§Ü‡§π‡•á‡§§?",
                "‡§ú‡§Ø ‡§∂‡•ç‡§∞‡•Ä‡§Æ‡§®‡•ç‡§®‡§æ‡§∞‡§æ‡§Ø‡§£! üôè ‡§∏‡§∞‡•ç‡§µ ‡§ï‡§æ‡§π‡•Ä ‡§Ö‡§¶‡•ç‡§≠‡•Å‡§§ ‡§Ü‡§π‡•á, ‡§ß‡§®‡•ç‡§Ø‡§µ‡§æ‡§¶! ‡§Ü‡§ú ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡•á‡§ö‡§æ ‡§∂‡•ã‡§ß ‡§ò‡•á‡§£‡•ç‡§Ø‡§æ‡§§ ‡§Æ‡•Ä ‡§§‡•Å‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ï‡§∂‡•Ä ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§§‡•ã?"
            ]
        }
        language_responses = responses.get(language, responses['english'])
        return random.choice(language_responses)

def get_no_answer_response(language: str) -> str:
    """Get natural no answer response in the detected language"""
    import random
    
    responses = {
        'english': [
            "I apologize, but I couldn't find relevant information about this topic in the Bhagavad Gita transcripts. Could you try rephrasing your question or ask about something else?",
            "Sorry, I don't have information about this specific topic in the Bhagavad Gita content I have access to. Perhaps you could ask about a different aspect of the Gita?",
            "I'm afraid I couldn't locate relevant details about this topic in the Bhagavad Gita transcripts. Would you like to explore a different question about the Gita?",
            "Unfortunately, I don't have the specific information you're looking for in the Bhagavad Gita content. Could you try asking about another topic from the Gita?",
            "I couldn't find relevant information about this topic in the Bhagavad Gita transcripts. Feel free to ask about other aspects of Krishna's teachings!"
        ],
        'hindi': [
            "‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•Å‡§ù‡•á ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§µ‡§ø‡§∑‡§Ø ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§Ö‡§™‡§®‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§¨‡§®‡§æ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§æ ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?",
            "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•Ä ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§µ‡§ø‡§∑‡§Ø ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§∂‡§æ‡§Ø‡§¶ ‡§Ü‡§™ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§Ö‡§®‡•ç‡§Ø ‡§™‡§π‡§≤‡•Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?",
            "‡§Æ‡•Å‡§ù‡•á ‡§ñ‡•á‡§¶ ‡§π‡•à ‡§ï‡§ø ‡§Æ‡•à‡§Ç ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§µ‡§ø‡§∑‡§Ø ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§®‡§π‡•Ä‡§Ç ‡§¢‡•Ç‡§Ç‡§¢ ‡§∏‡§ï‡§æ‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•ã‡§à ‡§Ö‡§®‡•ç‡§Ø ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á?",
            "‡§¶‡•Å‡§∞‡•ç‡§≠‡§æ‡§ó‡•ç‡§Ø ‡§∏‡•á, ‡§Æ‡•á‡§∞‡•á ‡§™‡§æ‡§∏ ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•Ä ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§Ü‡§™ ‡§ú‡•ã ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç, ‡§µ‡§π ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§Ö‡§®‡•ç‡§Ø ‡§µ‡§ø‡§∑‡§Ø ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç?",
            "‡§Æ‡•Å‡§ù‡•á ‡§≠‡§ó‡§µ‡§¶ ‡§ó‡•Ä‡§§‡§æ ‡§ï‡•á ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§á‡§∏ ‡§µ‡§ø‡§∑‡§Ø ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§æ‡§∏‡§Ç‡§ó‡§ø‡§ï ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡•Ä‡•§ ‡§ï‡•É‡§∑‡•ç‡§£ ‡§ï‡•Ä ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§Ö‡§®‡•ç‡§Ø ‡§™‡§π‡§≤‡•Å‡§ì‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§µ‡§§‡§Ç‡§§‡•ç‡§∞ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡•á‡§Ç!"
        ],
        'telugu': [
            "‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞≤‡±á‡∞ñ‡∞æ‡∞≤‡∞≤‡±ã ‡∞à ‡∞Ö‡∞Ç‡∞∂‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞®‡∞æ‡∞ï‡±Å ‡∞¶‡±ä‡∞∞‡∞ï‡∞≤‡±á‡∞¶‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞®‡±Å ‡∞Æ‡∞≥‡±ç‡∞≤‡±Ä ‡∞∞‡±Ç‡∞™‡±ä‡∞Ç‡∞¶‡∞ø‡∞Ç‡∞ö‡∞ó‡∞≤‡∞∞‡∞æ ‡∞≤‡±á‡∞¶‡∞æ ‡∞µ‡±á‡∞∞‡±á‡∞¶‡±à‡∞®‡∞æ ‡∞Ö‡∞°‡∞ó‡∞ó‡∞≤‡∞∞‡∞æ?",
            "‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞®‡∞æ ‡∞µ‡∞¶‡±ç‡∞¶ ‡∞â‡∞®‡±ç‡∞® ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç‡∞≤‡±ã ‡∞à ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï ‡∞Ö‡∞Ç‡∞∂‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞≤‡±á‡∞¶‡±Å. ‡∞¨‡∞π‡±Å‡∞∂‡∞æ ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ó‡±Ä‡∞§ ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞µ‡±á‡∞∞‡±á ‡∞Ö‡∞Ç‡∞∂‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ö‡∞°‡∞ó‡∞µ‡∞ö‡±ç‡∞ö‡±Å?",
            "‡∞ï‡±ç‡∞∑‡∞Æ‡∞ø‡∞Ç‡∞ö‡∞Ç‡∞°‡∞ø, ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞≤‡±á‡∞ñ‡∞æ‡∞≤‡∞≤‡±ã ‡∞à ‡∞Ö‡∞Ç‡∞∂‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞µ‡∞ø‡∞µ‡∞∞‡∞æ‡∞≤‡∞®‡±Å ‡∞®‡±á‡∞®‡±Å ‡∞ï‡∞®‡±Å‡∞ó‡±ä‡∞®‡∞≤‡±á‡∞ï‡∞™‡±ã‡∞Ø‡∞æ‡∞®‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ó‡±Ä‡∞§ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞µ‡±á‡∞∞‡±á ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞® ‡∞Ö‡∞°‡∞ó‡∞æ‡∞≤‡∞®‡±Å‡∞ï‡±Å‡∞Ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡∞æ?",
            "‡∞¶‡±Å‡∞∞‡∞¶‡±É‡∞∑‡±ç‡∞ü‡∞µ‡∞∂‡∞æ‡∞§‡±ç‡∞§‡±Å, ‡∞®‡∞æ ‡∞µ‡∞¶‡±ç‡∞¶ ‡∞â‡∞®‡±ç‡∞® ‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç‡∞≤‡±ã ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞µ‡±Ü‡∞§‡±Å‡∞ï‡±Å‡∞§‡±Å‡∞®‡±ç‡∞® ‡∞™‡±ç‡∞∞‡∞§‡±ç‡∞Ø‡±á‡∞ï ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞≤‡±á‡∞¶‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞ó‡±Ä‡∞§ ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞µ‡±á‡∞∞‡±á ‡∞Ö‡∞Ç‡∞∂‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ö‡∞°‡∞ó‡∞µ‡∞ö‡±ç‡∞ö‡∞æ?",
            "‡∞≠‡∞ó‡∞µ‡∞¶‡±ç‡∞ó‡±Ä‡∞§ ‡∞™‡±ç‡∞∞‡∞§‡∞ø‡∞≤‡±á‡∞ñ‡∞æ‡∞≤‡∞≤‡±ã ‡∞à ‡∞Ö‡∞Ç‡∞∂‡∞Ç ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞∏‡∞Ç‡∞¨‡∞Ç‡∞ß‡∞ø‡∞§ ‡∞∏‡∞Æ‡∞æ‡∞ö‡∞æ‡∞∞‡∞Ç ‡∞®‡∞æ‡∞ï‡±Å ‡∞¶‡±ä‡∞∞‡∞ï‡∞≤‡±á‡∞¶‡±Å. ‡∞ï‡±É‡∞∑‡±ç‡∞£‡±Å‡∞°‡∞ø ‡∞¨‡±ã‡∞ß‡∞®‡∞≤ ‡∞Ø‡±ä‡∞ï‡±ç‡∞ï ‡∞á‡∞§‡∞∞ ‡∞Ö‡∞Ç‡∞∂‡∞æ‡∞≤ ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø ‡∞Ö‡∞°‡∞ó‡∞°‡∞æ‡∞®‡∞ø‡∞ï‡∞ø ‡∞∏‡±ç‡∞µ‡±á‡∞ö‡±ç‡∞õ‡∞ó‡∞æ ‡∞â‡∞Ç‡∞°‡∞Ç‡∞°‡∞ø!"
        ],
        'kannada': [
            "‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤≤‡≥á‡≤ñ‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤à ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤ø‡≤§ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤ï‡≤Ç‡≤°‡≥Å‡≤π‡≤ø‡≤°‡≤ø‡≤Ø‡≤≤‡≤ø‡≤≤‡≥ç‡≤≤. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤®‡≤ø‡≤Æ‡≥ç‡≤Æ ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü ‡≤∞‡≥Ç‡≤™‡≤ø‡≤∏‡≤¨‡≤π‡≥Å‡≤¶‡≥á ‡≤Ö‡≤•‡≤µ‡≤æ ‡≤¨‡≥á‡≤∞‡≥Ü ‡≤Ø‡≤æ‡≤µ‡≥Å‡≤¶‡≤æ‡≤¶‡≤∞‡≥Ç ‡≤ï‡≥á‡≤≥‡≤¨‡≤π‡≥Å‡≤¶‡≥á?",
            "‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤®‡≤®‡≥ç‡≤®‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤à ‡≤®‡≤ø‡≤∞‡≥ç‡≤¶‡≤ø‡≤∑‡≥ç‡≤ü ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø ‡≤á‡≤≤‡≥ç‡≤≤. ‡≤¨‡≤π‡≥Å‡≤∂‡≤É ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤á‡≤§‡≤∞ ‡≤Ö‡≤Ç‡≤∂‡≤ó‡≤≥ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤ï‡≥á‡≤≥‡≤¨‡≤π‡≥Å‡≤¶‡≥Å?",
            "‡≤ï‡≥ç‡≤∑‡≤Æ‡≤ø‡≤∏‡≤ø, ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤≤‡≥á‡≤ñ‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤à ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤ø‡≤§ ‡≤µ‡≤ø‡≤µ‡≤∞‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤ï‡≤Ç‡≤°‡≥Å‡≤π‡≤ø‡≤°‡≤ø‡≤Ø‡≤≤‡≤ø‡≤≤‡≥ç‡≤≤. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤¨‡≥á‡≤∞‡≥Ü ‡≤™‡≥ç‡≤∞‡≤∂‡≥ç‡≤®‡≥Ü ‡≤ï‡≥á‡≤≥‡≤≤‡≥Å ‡≤¨‡≤Ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥Ä‡≤∞‡≤æ?",
            "‡≤¶‡≥Å‡≤∞‡≤¶‡≥É‡≤∑‡≥ç‡≤ü‡≤µ‡≤∂‡≤æ‡≤§‡≥ç, ‡≤®‡≤®‡≥ç‡≤®‡≤≤‡≥ç‡≤≤‡≤ø‡≤∞‡≥Å‡≤µ ‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤π‡≥Å‡≤°‡≥Å‡≤ï‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤∞‡≥Å‡≤µ ‡≤®‡≤ø‡≤∞‡≥ç‡≤¶‡≤ø‡≤∑‡≥ç‡≤ü ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø ‡≤á‡≤≤‡≥ç‡≤≤. ‡≤®‡≥Ä‡≤µ‡≥Å ‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤¨‡≥á‡≤∞‡≥Ü ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤ï‡≥á‡≤≥‡≤¨‡≤π‡≥Å‡≤¶‡≥á?",
            "‡≤≠‡≤ó‡≤µ‡≤¶‡≥ç‡≤ó‡≥Ä‡≤§‡≥Ü‡≤Ø ‡≤™‡≥ç‡≤∞‡≤§‡≤ø‡≤≤‡≥á‡≤ñ‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø ‡≤à ‡≤µ‡≤ø‡≤∑‡≤Ø‡≤¶ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤∏‡≤Ç‡≤¨‡≤Ç‡≤ß‡≤ø‡≤§ ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤®‡≤æ‡≤®‡≥Å ‡≤ï‡≤Ç‡≤°‡≥Å‡≤π‡≤ø‡≤°‡≤ø‡≤Ø‡≤≤‡≤ø‡≤≤‡≥ç‡≤≤. ‡≤ï‡≥É‡≤∑‡≥ç‡≤£‡≤® ‡≤¨‡≥ã‡≤ß‡≤®‡≥Ü‡≤ó‡≤≥ ‡≤á‡≤§‡≤∞ ‡≤Ö‡≤Ç‡≤∂‡≤ó‡≤≥ ‡≤¨‡≤ó‡≥ç‡≤ó‡≥Ü ‡≤ï‡≥á‡≤≥‡≤≤‡≥Å ‡≤∏‡≥ç‡≤µ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø ‡≤á‡≤∞‡≤ø!"
        ],
        'marathi': [
            "‡§Æ‡§æ‡§´ ‡§ï‡§∞‡§æ, ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Ø‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§æ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§Æ‡§≤‡§æ ‡§∏‡§æ‡§™‡§°‡§≤‡•Ä ‡§®‡§æ‡§π‡•Ä. ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§§‡•Å‡§Æ‡§ö‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Å‡§®‡•ç‡§π‡§æ ‡§§‡§Ø‡§æ‡§∞ ‡§ï‡§∞‡•Ç ‡§∂‡§ï‡§§‡§æ ‡§ï‡§æ ‡§ï‡§ø‡§Ç‡§µ‡§æ ‡§ï‡§æ‡§π‡•Ä‡§§‡§∞‡•Ä ‡§µ‡•á‡§ó‡§≥‡•á ‡§µ‡§ø‡§ö‡§æ‡§∞‡•Ç ‡§∂‡§ï‡§§‡§æ ‡§ï‡§æ?",
            "‡§Æ‡§æ‡§´ ‡§ï‡§∞‡§æ, ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ‡§ï‡§°‡•á ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä‡§§ ‡§Ø‡§æ ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§µ‡§ø‡§∑‡§Ø‡§æ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä. ‡§ï‡§¶‡§æ‡§ö‡§ø‡§§ ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ó‡•Ä‡§§‡•á‡§ö‡•ç‡§Ø‡§æ ‡§¶‡•Å‡§∏‡§±‡•ç‡§Ø‡§æ ‡§™‡•à‡§≤‡•Ç‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§µ‡§ø‡§ö‡§æ‡§∞‡•Ç ‡§∂‡§ï‡§§‡§æ?",
            "‡§Æ‡§æ‡§ù‡•Ä ‡§ñ‡•á‡§¶ ‡§Ü‡§π‡•á ‡§ï‡•Ä ‡§Æ‡•Ä ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Ø‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§æ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§§‡§™‡§∂‡•Ä‡§≤ ‡§∂‡•ã‡§ß‡•Ç ‡§∂‡§ï‡§≤‡•ã ‡§®‡§æ‡§π‡•Ä. ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ó‡•Ä‡§§‡•á‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§¶‡•Å‡§∏‡§∞‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§µ‡§ø‡§ö‡§æ‡§∞‡•Ç ‡§á‡§ö‡•ç‡§õ‡§ø‡§§‡§æ ‡§ï‡§æ?",
            "‡§¶‡•Å‡§∞‡•ç‡§¶‡•à‡§µ‡§æ‡§®‡•á, ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ‡§ï‡§°‡•á ‡§Ö‡§∏‡§≤‡•á‡§≤‡•ç‡§Ø‡§æ ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ ‡§∏‡§æ‡§Æ‡§ó‡•ç‡§∞‡•Ä‡§§ ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§∂‡•ã‡§ß‡§§ ‡§Ö‡§∏‡§≤‡•á‡§≤‡•Ä ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§®‡§æ‡§π‡•Ä. ‡§§‡•Å‡§Æ‡•ç‡§π‡•Ä ‡§ó‡•Ä‡§§‡•á‡§ö‡•ç‡§Ø‡§æ ‡§¶‡•Å‡§∏‡§±‡•ç‡§Ø‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§æ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§µ‡§ø‡§ö‡§æ‡§∞‡•Ç ‡§∂‡§ï‡§§‡§æ ‡§ï‡§æ?",
            "‡§Æ‡§≤‡§æ ‡§≠‡§ó‡§µ‡§¶‡•ç‡§ó‡•Ä‡§§‡§æ ‡§™‡•ç‡§∞‡§§‡§ø‡§≤‡•á‡§ñ‡§æ‡§Ç‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§Ø‡§æ ‡§µ‡§ø‡§∑‡§Ø‡§æ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§∏‡§Ç‡§¨‡§Ç‡§ß‡§ø‡§§ ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§∏‡§æ‡§™‡§°‡§≤‡•Ä ‡§®‡§æ‡§π‡•Ä. ‡§ï‡•É‡§∑‡•ç‡§£‡§æ‡§ö‡•ç‡§Ø‡§æ ‡§∂‡§ø‡§ï‡§µ‡§£‡•Ä‡§Ç‡§ö‡•ç‡§Ø‡§æ ‡§á‡§§‡§∞ ‡§™‡•à‡§≤‡•Ç‡§Ç‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§µ‡§ø‡§ö‡§æ‡§∞‡§£‡•ç‡§Ø‡§æ‡§∏‡§æ‡§†‡•Ä ‡§Æ‡•ã‡§ï‡§≥‡•á‡§™‡§£‡§æ‡§®‡•á ‡§µ‡§æ‡§ü ‡§™‡§π‡§æ!"
        ]
    }
    
    language_responses = responses.get(language, responses['english'])
    return random.choice(language_responses)

@router.post("/")
def chat_post(request: ChatRequest, fastapi_request: Request, fastapi_response: Response):
    """Chat endpoint that accepts POST requests with JSON body"""
    # Prefer explicit session_id, then header, then cookie
    incoming_session_id = request.session_id or fastapi_request.headers.get("X-Session-Id") or fastapi_request.cookies.get("session_id")
    result = process_chat_query(request.query, incoming_session_id)
    # Persist session in cookie for continuity when client doesn't send it explicitly
    if result and isinstance(result, dict) and result.get("session_id"):
        fastapi_response.set_cookie(
            key="session_id",
            value=result["session_id"],
            httponly=False,
            samesite="lax",
            max_age=60 * 60 * 24 * 7
        )
    return result

@router.get("/")
def chat_get(
    fastapi_request: Request,
    fastapi_response: Response,
    query: str = Query(..., description="Your question about the Bhagavad Gita"),
    session_id: Optional[str] = Query(None, description="Session ID for conversation history")
):
    """Chat endpoint that accepts GET requests with query parameter"""
    incoming_session_id = session_id or fastapi_request.headers.get("X-Session-Id") or fastapi_request.cookies.get("session_id")
    result = process_chat_query(query, incoming_session_id)
    if result and isinstance(result, dict) and result.get("session_id"):
        fastapi_response.set_cookie(
            key="session_id",
            value=result["session_id"],
            httponly=False,
            samesite="lax",
            max_age=60 * 60 * 24 * 7
        )
    return result

def process_chat_query(query: str, session_id: Optional[str] = None):
    """Process the chat query and return response with conversation history"""
    try:
        if not query.strip():
            raise HTTPException(status_code=400, detail="Query cannot be empty")
        
        # Get or create session ID for conversation tracking
        session_id = get_or_create_session_id(session_id)
        
        # Detect language and check if it's a greeting
        is_greeting_detected, detected_language = detect_language_and_greeting(query)
        
        # Get conversation context
        conversation_context = get_conversation_context(session_id, detected_language)
        
        # Check if it's a greeting first
        if is_greeting_detected:
            answer = get_greeting_response(detected_language, query)
            # Add to conversation history
            add_to_conversation_history(session_id, query, answer, detected_language)
            return {
                "answer": answer,
                "confidence": 2.0,
                "sources": [],
                "session_id": session_id
            }
        
        # Generate embedding for the query augmented with recent conversation context
        augmented_query = f"{conversation_context}\nCurrent Question: {query}" if conversation_context else query
        query_vector = embeddings.embed_text(augmented_query)
        
        # Search for similar chunks in Pinecone
        results = pinecone_client.index.query(
            vector=query_vector,
            top_k=3,  # Reduced for faster response
            include_metadata=True
        )

        if not results.matches or results.matches[0].score < 0.5:  # Lowered threshold slightly
            answer = get_no_answer_response(detected_language)
            # Add to conversation history
            add_to_conversation_history(session_id, query, answer, detected_language)
            return {
                "answer": answer,
                "confidence": results.matches[0].score if results.matches else 0,
                "sources": [],
                "session_id": session_id
            }

        # Prepare context from top matches
        context_chunks = []
        for match in results.matches:
            if match.score > 0.4:  # Lowered threshold for more context
                context_chunks.append({
                    "text": match.metadata["text"],
                    "chunk_id": match.metadata.get("chunk_id", "unknown"),
                    "score": match.score
                })
        
        # Create context string
        context = " ".join([chunk["text"] for chunk in context_chunks])
        
        # Generate answer using LLM with language instruction and structured conversation history
        structured_messages = get_structured_conversation_messages(session_id, detected_language)
        answer = llm.generate_answer_with_language_structured(
            query=query,
            context=context,
            language=detected_language,
            history_messages=structured_messages
        )
        
        # Add to conversation history
        add_to_conversation_history(session_id, query, answer, detected_language)
        
        return {
            "answer": answer,
            "confidence": results.matches[0].score,
            "sources": context_chunks[:3],  # Return top 3 sources
            "session_id": session_id
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error processing query: {str(e)}")

@router.get("/history")
def get_chat_history(session_id: str = Query(..., description="Session ID to retrieve history for")):
    """Get conversation history for a session"""
    if session_id not in conversation_history:
        return {"history": []}
    
    # Return last 10 conversation turns
    history = conversation_history[session_id][-10:]
    return {"history": history}

@router.get("/health")
def health_check():
    """Health check endpoint"""
    return {"status": "healthy", "message": "Chat service is running"}